# MeltingPoint Backend - CLAUDE.md

## Descripci√≥n
Backend FastAPI para predicci√≥n de puntos de fusi√≥n moleculares usando **Ensemble (XGB+LGB+CAT) + ChemProp D-MPNN**.

## üéØ Rendimiento del Modelo

| Configuraci√≥n | MAE (K) | Estado |
|---------------|---------|--------|
| ChemProp solo | 28.85 | ‚úÖ Disponible |
| Ensemble solo | 26.64 | ‚úÖ Disponible |
| **Ensemble + ChemProp** | **22.80** | ‚≠ê **Mejor (Kaggle)** |

## Instalaci√≥n en Nueva Computadora

```bash
# 1. Crear entorno virtual
python -m venv .venv
.venv\Scripts\activate      # Windows
source .venv/bin/activate   # Linux/Mac

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. ‚ö†Ô∏è OBLIGATORIO: Aplicar parche para PyTorch 2.6+
python patch_chemprop_torch.py

# 4. Entrenar ensemble (si no existe)
cd ../src
python train_ensemble_production.py
cd ../backend

# 5. Ejecutar servidor
uvicorn app.main:app --reload --port 8000
```

### Verificar instalaci√≥n correcta
Debes ver en los logs:
```
INFO: ChemProp 1.6.1 detectado correctamente.
INFO: ChemProp habilitado con 5 checkpoints.
INFO: Ensemble cargado con 15 modelos.
INFO: Modo COMBINADO activo (MAE ~22.80 K)
```

## Stack Tecnol√≥gico
- **Framework**: FastAPI 0.121+
- **ML Models**: 
  - ChemProp 1.6.1 (D-MPNN)
  - XGBoost, LightGBM, CatBoost (Ensemble)
- **Qu√≠mica**: RDKit 2025.9+
- **Data**: pandas, numpy, joblib
- **Python**: 3.11+

## Estructura
```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # FastAPI endpoints
‚îÇ   ‚îú‚îÄ‚îÄ ml_service.py     # Predicciones (Ensemble + ChemProp)
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py        # Pydantic models
‚îÇ   ‚îî‚îÄ‚îÄ config.py         # Configuraci√≥n
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ model_chemprop/   # 5 folds ChemProp
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fold_0/model_0/model.pt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fold_1/model_0/model.pt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fold_2/model_0/model.pt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fold_3/model_0/model.pt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fold_4/model_0/model.pt
‚îÇ   ‚îú‚îÄ‚îÄ ensemble_predictor.joblib  # ‚¨ÖÔ∏è XGB+LGB+CAT
‚îÇ   ‚îú‚îÄ‚îÄ best_params_paso6.json     # Hiperpar√°metros
‚îÇ   ‚îî‚îÄ‚îÄ model.joblib               # Fallback sklearn
‚îú‚îÄ‚îÄ patch_chemprop_torch.py
‚îî‚îÄ‚îÄ requirements.txt
```

## Modelo H√≠brido

### ChemProp D-MPNN
| Par√°metro | Valor |
|-----------|-------|
| Hidden Size | 300 |
| Depth | 6 |
| Folds | 5 |
| MAE | 28.85 K |

### Ensemble (XGB + LGB + CAT)
| Modelo | Peso | MAE Individual |
|--------|------|----------------|
| XGBoost | 35% | ~28.5 K |
| LightGBM | 30% | ~29.5 K |
| CatBoost | 35% | ~28.8 K |
| **Ensemble** | - | **26.64 K** |

### Combinaci√≥n √ìptima
```
Predicci√≥n = 20% √ó ChemProp + 80% √ó Ensemble
MAE = 22.80 K (Kaggle)
```

## üéØ Sistema de Toma de Decisiones

El backend soporta un sistema completo de toma de decisiones con tres fuentes de datos:

| Fuente | Color | Cantidad | Descripci√≥n |
|--------|-------|----------|-------------|
| **Train** | üü¢ Verde | 2,662 | Datos reales con Tm medido experimentalmente |
| **Test** | üîµ Azul | 666 | Predicciones del modelo (MAE ~22.80 K) |
| **User** | üü† Naranja | Variable | Compuestos agregados por el usuario |

### Interpretaci√≥n de Incertidumbre

- **MAE del modelo**: ¬±22.80 K (intervalo de confianza)
- **Significado pr√°ctico**: Una predicci√≥n de 350 K significa que el Tm real est√° probablemente entre 327-373 K
- **Para decisiones cr√≠ticas**: Considerar el rango completo de incertidumbre

### Datasets Procesados

```
data/processed/
‚îú‚îÄ‚îÄ dataset_train.csv    # 2,662 filas (id, smiles, Tm real, source='train')
‚îî‚îÄ‚îÄ dataset_test.csv     # 666 filas (id, smiles, Tm predicho, source='test')
```

## Endpoints Principales

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| GET | `/health` | Health check |
| GET | `/model-info` | Info del modelo (MAE, configuraci√≥n) |
| GET | `/data-all` | **Todos los datos (train+test+user) con fuente** |
| GET | `/compound-name` | **Nombre del compuesto desde PubChem** |
| POST | `/validate-smiles` | Validar SMILES |
| POST | `/compounds` | Crear compuesto + predicci√≥n |
| GET | `/compounds` | Listar compuestos usuario |
| DELETE | `/compounds/{id}` | Eliminar compuesto |
| GET | `/stats` | Estad√≠sticas |
| GET | `/predict-all` | Todas las predicciones (test only) |
| GET | `/predictions/by-functional-group` | **An√°lisis por grupos funcionales** |
| GET | `/predictions/by-molecule-size` | An√°lisis por tama√±o molecular |
| GET | `/predictions/distribution` | Distribuci√≥n por categor√≠as de Tm |

## üìä An√°lisis por Grupos Funcionales

### ¬øPor qu√© es importante?

El endpoint `/predictions/by-functional-group` es clave para la toma de decisiones porque:

1. **Base cient√≠fica**: Los grupos funcionales determinan las interacciones intermoleculares
   - **Puentes de hidr√≥geno**: OH, NH2, COOH aumentan Tm
   - **œÄ-stacking**: Grupos arom√°ticos aumentan Tm
   - **Polaridad**: Afecta la red cristalina

2. **Uso pr√°ctico para decisiones**:
   - Comparar tu compuesto con otros del mismo grupo
   - Verificar si la predicci√≥n es consistente con la estructura
   - Identificar si tu compuesto est√° en un rango t√≠pico

3. **C√≥mo defenderlo**:
   > "El an√°lisis por grupos funcionales permite validar predicciones comparando
   > con compuestos de estructura similar. Si tu mol√©cula tiene grupo OH,
   > puedes ver el rango t√≠pico de Tm para alcoholes y verificar que
   > la predicci√≥n sea consistente."

### Ejemplo de uso

```python
# Consultar promedios por grupo funcional
GET /predictions/by-functional-group

# Respuesta incluye:
{
  "groups": [
    {"name": "Hydroxyl (OH)", "count": 450, "avg_tm": 320.5, ...},
    {"name": "Amine (NH2)", "count": 280, "avg_tm": 315.2, ...},
    ...
  ]
}
```

## üìà Interpretaci√≥n del MAE

### ¬øPor qu√© usamos MAE de Kaggle (22.80 K) y no el de entrenamiento?

| M√©trica | Valor | Descripci√≥n |
|---------|-------|-------------|
| **MAE Kaggle** | 22.80 K | Error en datos NO vistos (test set real) |
| MAE ChemProp OOF | 28.85 K | Error en validaci√≥n cruzada |
| MAE Ensemble OOF | 26.64 K | Error en validaci√≥n cruzada |

**El MAE de Kaggle es m√°s v√°lido porque**:
1. Mide el error en datos completamente nuevos
2. No hay riesgo de overfitting
3. Es la m√©trica oficial de la competencia
4. Representa el rendimiento real de generalizaci√≥n

**C√≥mo comunicarlo**:
> "La incertidumbre de ¬±22.80 K est√° validada en el test set de Kaggle,
> que representa datos que el modelo nunca vio durante el entrenamiento.
> Esto es una estimaci√≥n conservadora del error esperado en nuevos compuestos."

## Ejemplo de Uso

```bash
# Crear compuesto (Water)
curl -X POST "http://localhost:8000/compounds" \
  -H "Content-Type: application/json" \
  -d '{"smiles": "O", "name": "Water"}'

# Respuesta esperada (con modelo combinado):
{
  "id": "USR_001",
  "smiles": "O",
  "name": "Water",
  "Tm_pred": 272.17,           # Real: 273.15 K ‚úì
  "Tm_celsius": -0.98,
  "uncertainty": "¬±23 K",
  "method": "combined (cp=20%)"
}

# Obtener nombre de compuesto desde PubChem
curl "http://localhost:8000/compound-name?smiles=CCO"
# Respuesta: {"smiles": "CCO", "name": "ethanol", "source": "pubchem"}

# Obtener todos los datos (train+test+user)
curl "http://localhost:8000/data-all"
# Respuesta: [{"id": 1, "smiles": "...", "Tm_pred": 350.5, "source": "train"}, ...]
```

## Gu√≠a de Uso para Decisiones

### Cu√°ndo Confiar en las Predicciones

| Escenario | Recomendaci√≥n |
|-----------|---------------|
| Predicci√≥n cerca de datos train | ‚úÖ Mayor confianza |
| Predicci√≥n en extremos (< 100 K o > 800 K) | ‚ö†Ô∏è Menos datos de referencia |
| Mol√©cula muy diferente al dataset | ‚ö†Ô∏è Extrapolar con cautela |
| Decisi√≥n cr√≠tica de seguridad | üî¨ Verificar experimentalmente |

### Flujo de Trabajo Recomendado

1. **Validar SMILES** ‚Üí `/validate-smiles`
2. **Verificar nombre** ‚Üí `/compound-name` (PubChem)
3. **Comparar con dataset** ‚Üí Ver distribuci√≥n en `/data-all`
4. **Predecir** ‚Üí `/compounds` (crea registro con predicci√≥n)
5. **Interpretar** ‚Üí Considerar ¬±22.80 K de incertidumbre

## requirements.txt
```txt
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.0.0
python-multipart>=0.0.6
pandas>=2.0.0
numpy==1.26.4
scikit-learn>=1.3.0
joblib>=1.3.0
rdkit>=2023.03.1
chemprop==1.6.1
torch>=2.0.0
xgboost>=2.0.0
lightgbm>=4.0.0
catboost>=1.2.0
```

## Troubleshooting

| Problema | Soluci√≥n |
|----------|----------|
| "weights_only load failed" | `python patch_chemprop_torch.py` |
| MAE 28.85 (no 22.80) | Falta ensemble: `cd ../src && python train_ensemble_production.py` |
| "Ensemble no cargado" | Verificar que existe `models/ensemble_predictor.joblib` |
| Predicci√≥n lenta (10-30s) | Normal para ChemProp |

## Docs
- Swagger: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc